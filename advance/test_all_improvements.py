#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ‰€æœ‰è®­ç»ƒè„šæœ¬çš„æ”¹è¿›åŠŸèƒ½
éªŒè¯æ–°å¢çš„éªŒè¯é›†è¯„ä¼°å’Œä»»åŠ¡ç‰¹å®šæŒ‡æ ‡è®¡ç®—åŠŸèƒ½
"""

import os
import sys
import math
import torch
import torch.nn.functional as F

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.abspath('.'))

def test_pretrain_metrics():
    """æµ‹è¯•é¢„è®­ç»ƒæŒ‡æ ‡è®¡ç®—"""
    print("=" * 50)
    print("æµ‹è¯•é¢„è®­ç»ƒæŒ‡æ ‡è®¡ç®—")
    print("=" * 50)
    
    # æµ‹è¯•PPLè®¡ç®—
    loss_values = [0.1, 1.0, 2.3, 5.0, 10.0, 15.0]
    
    for loss in loss_values:
        ppl = math.exp(loss) if loss < 10 else float('inf')
        print(f"Loss: {loss:.1f} -> PPL: {ppl:.3f}" if ppl != float('inf') else f"Loss: {loss:.1f} -> PPL: inf")
    
    print("é¢„è®­ç»ƒæŒ‡æ ‡æµ‹è¯•å®Œæˆï¼\n")

def test_sft_metrics():
    """æµ‹è¯•SFTæŒ‡æ ‡è®¡ç®—"""
    print("=" * 50)
    print("æµ‹è¯•SFTæŒ‡æ ‡è®¡ç®—")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿlogitså’Œlabels
    batch_size, seq_len, vocab_size = 2, 10, 1000
    logits = torch.randn(batch_size, seq_len, vocab_size)
    labels = torch.randint(0, vocab_size, (batch_size, seq_len))
    loss_mask = torch.ones(batch_size, seq_len)
    
    with torch.no_grad():
        # è®¡ç®—å›°æƒ‘åº¦
        loss_fct = torch.nn.CrossEntropyLoss(reduction='none')
        loss = loss_fct(logits.view(-1, vocab_size), labels.view(-1)).view(labels.size())
        masked_loss = (loss * loss_mask).sum() / loss_mask.sum()
        ppl = torch.exp(masked_loss) if masked_loss < 10 else torch.tensor(float('inf'))
        
        # è®¡ç®—å‡†ç¡®ç‡
        predictions = torch.argmax(logits, dim=-1)
        correct = (predictions == labels) & (loss_mask.bool())
        accuracy = correct.sum().float() / loss_mask.sum().float()
        
        # è®¡ç®—top-5å‡†ç¡®ç‡
        _, top5_preds = torch.topk(logits, k=5, dim=-1)
        top5_correct = (top5_preds == labels.unsqueeze(-1)).any(dim=-1) & (loss_mask.bool())
        top5_accuracy = top5_correct.sum().float() / loss_mask.sum().float()
    
    print(f"SFTæŒ‡æ ‡:")
    print(f"  Loss: {masked_loss:.3f}")
    print(f"  PPL: {ppl:.3f}")
    print(f"  Accuracy: {accuracy:.3f}")
    print(f"  Top-5 Accuracy: {top5_accuracy:.3f}")
    print("SFTæŒ‡æ ‡æµ‹è¯•å®Œæˆï¼\n")

def test_lora_metrics():
    """æµ‹è¯•LoRAæŒ‡æ ‡è®¡ç®—"""
    print("=" * 50)
    print("æµ‹è¯•LoRAæŒ‡æ ‡è®¡ç®—")
    print("=" * 50)
    
    # æ¨¡æ‹ŸLoRAå‚æ•°ç»Ÿè®¡
    total_params = 26000000  # 26Må‚æ•°
    lora_params = 260000     # 260K LoRAå‚æ•°
    param_efficiency = lora_params / total_params
    
    print(f"LoRAæŒ‡æ ‡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  LoRAå‚æ•°é‡: {lora_params:,}")
    print(f"  å‚æ•°æ•ˆç‡: {param_efficiency:.6f} ({param_efficiency*100:.2f}%)")
    print("LoRAæŒ‡æ ‡æµ‹è¯•å®Œæˆï¼\n")

def test_dpo_metrics():
    """æµ‹è¯•DPOæŒ‡æ ‡è®¡ç®—"""
    print("=" * 50)
    print("æµ‹è¯•DPOæŒ‡æ ‡è®¡ç®—")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿchosenå’Œrejectedçš„æ¦‚ç‡
    batch_size = 4
    chosen_probs = torch.randn(batch_size) * 0.5 + 1.0  # ç¨é«˜çš„æ¦‚ç‡
    rejected_probs = torch.randn(batch_size) * 0.5 + 0.5  # ç¨ä½çš„æ¦‚ç‡
    ref_chosen_probs = torch.randn(batch_size) * 0.3 + 0.8
    ref_rejected_probs = torch.randn(batch_size) * 0.3 + 0.6
    beta = 0.1
    
    with torch.no_grad():
        # è®¡ç®—log ratios
        pi_logratios = chosen_probs - rejected_probs
        ref_logratios = ref_chosen_probs - ref_rejected_probs
        
        # è®¡ç®—åå¥½å‡†ç¡®ç‡
        preference_accuracy = (pi_logratios > 0).float().mean()
        
        # è®¡ç®—å¥–åŠ±å·®å¼‚
        reward_margin = pi_logratios.mean()
        
        # è®¡ç®—éšå¼å¥–åŠ±
        chosen_rewards = beta * chosen_probs
        rejected_rewards = beta * rejected_probs
        
        # è®¡ç®—KLæ•£åº¦
        kl_divergence = (pi_logratios - ref_logratios).abs().mean()
    
    print(f"DPOæŒ‡æ ‡:")
    print(f"  åå¥½å‡†ç¡®ç‡: {preference_accuracy:.3f}")
    print(f"  å¥–åŠ±å·®å¼‚: {reward_margin:.3f}")
    print(f"  Chosenå¥–åŠ±å‡å€¼: {chosen_rewards.mean():.3f}")
    print(f"  Rejectedå¥–åŠ±å‡å€¼: {rejected_rewards.mean():.3f}")
    print(f"  KLæ•£åº¦: {kl_divergence:.3f}")
    print("DPOæŒ‡æ ‡æµ‹è¯•å®Œæˆï¼\n")

def test_data_split():
    """æµ‹è¯•æ•°æ®é›†åˆ†å‰²åŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯•æ•°æ®é›†åˆ†å‰²åŠŸèƒ½")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿä¸åŒå¤§å°çš„æ•°æ®é›†
    dataset_sizes = [100, 1000, 10000]
    val_ratios = [0.1, 0.15, 0.2]
    
    for dataset_size in dataset_sizes:
        for val_ratio in val_ratios:
            val_size = int(dataset_size * val_ratio)
            train_size = dataset_size - val_size
            
            print(f"æ•°æ®é›†å¤§å°: {dataset_size}, éªŒè¯é›†æ¯”ä¾‹: {val_ratio}")
            print(f"  è®­ç»ƒé›†: {train_size} æ ·æœ¬")
            print(f"  éªŒè¯é›†: {val_size} æ ·æœ¬")
            print(f"  éªŒè¯: {train_size + val_size == dataset_size}")
            print()
    
    print("æ•°æ®é›†åˆ†å‰²æµ‹è¯•å®Œæˆï¼\n")

def test_wandb_config():
    """æµ‹è¯•wandbé…ç½®"""
    print("=" * 50)
    print("æµ‹è¯•wandbé…ç½®")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿä¸åŒä»»åŠ¡çš„é…ç½®
    tasks = {
        "Pretrain": {
            "learning_rate": 5e-4,
            "epochs": 1,
            "batch_size": 32,
            "task_type": "Pretrain"
        },
        "SFT": {
            "learning_rate": 5e-5,
            "epochs": 2,
            "batch_size": 16,
            "task_type": "SFT"
        },
        "LoRA": {
            "learning_rate": 1e-4,
            "epochs": 3,
            "batch_size": 8,
            "task_type": "LoRA",
            "lora_name": "medical"
        },
        "DPO": {
            "learning_rate": 1e-8,
            "epochs": 2,
            "batch_size": 4,
            "task_type": "DPO"
        }
    }
    
    for task_name, config in tasks.items():
        print(f"{task_name} é…ç½®:")
        for key, value in config.items():
            print(f"  {key}: {value}")
        print()
    
    print("Wandbé…ç½®æµ‹è¯•å®Œæˆï¼\n")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•Mainè®­ç»ƒè„šæœ¬æ”¹è¿›åŠŸèƒ½")
    print("é¡¹ç›®: Improved llm model")
    print("=" * 80)
    
    test_pretrain_metrics()
    test_sft_metrics()
    test_lora_metrics()
    test_dpo_metrics()
    test_data_split()
    test_wandb_config()
    
    print("=" * 80)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)
    
    print("\nğŸ“‹ æ”¹è¿›åŠŸèƒ½æ€»ç»“:")
    print("1. âœ… é¢„è®­ç»ƒ: PPLæŒ‡æ ‡")
    print("2. âœ… SFT: PPL + å‡†ç¡®ç‡ + Top-5å‡†ç¡®ç‡")
    print("3. âœ… LoRA: PPL + å‡†ç¡®ç‡ + å‚æ•°æ•ˆç‡")
    print("4. âœ… DPO: åå¥½å‡†ç¡®ç‡ + å¥–åŠ±å·®å¼‚ + KLæ•£åº¦")
    print("5. âœ… æ‰€æœ‰è„šæœ¬: éªŒè¯é›†è¯„ä¼° + Wandbé›†æˆ")
    
    print("\nğŸ¯ ä½¿ç”¨è¯´æ˜:")
    print("æ‰€æœ‰è®­ç»ƒè„šæœ¬ç°åœ¨æ”¯æŒä»¥ä¸‹å‚æ•°:")
    print("  --use_wandb              # å¯ç”¨wandbè®°å½•")
    print("  --val_ratio 0.1          # éªŒè¯é›†æ¯”ä¾‹")
    print("  --eval_interval 500      # éªŒè¯è¯„ä¼°é—´éš”")
    print("  --wandb_project 'Improved llm model'  # é¡¹ç›®åç§°")

if __name__ == "__main__":
    main()

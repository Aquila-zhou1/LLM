"""
ç»„ä»¶æµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰é¢„è®­ç»ƒç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

import torch
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_data_loader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    logger.info("=== æµ‹è¯•æ•°æ®åŠ è½½å™¨ ===")
    try:
        from data.tinystories_loader import create_dataloaders
        
        # åˆ›å»ºå°è§„æ¨¡æ•°æ®åŠ è½½å™¨
        train_loader, val_loader, tokenizer = create_dataloaders(
            batch_size=2,
            max_length=128,
            num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            train_subset_size=10,
            val_subset_size=5
        )
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(train_loader))
        logger.info(f"âœ“ æ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡")
        logger.info(f"  æ‰¹æ¬¡å½¢çŠ¶: {batch['input_ids'].shape}")
        logger.info(f"  åˆ†è¯å™¨è¯è¡¨å¤§å°: {len(tokenizer)}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model():
    """æµ‹è¯•æ¨¡å‹"""
    logger.info("=== æµ‹è¯•æ¨¡å‹ ===")
    try:
        from model.gpt_model import GPTSmall
        
        # åˆ›å»ºå°æ¨¡å‹
        model = GPTSmall(
            vocab_size=50257,
            hidden_size=256,  # è¾ƒå°çš„éšè—å±‚ç”¨äºæµ‹è¯•
            num_layers=2,     # è¾ƒå°‘çš„å±‚æ•°ç”¨äºæµ‹è¯•
            num_heads=4,
            max_seq_len=128
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size, seq_len = 2, 64
        input_ids = torch.randint(0, 50257, (batch_size, seq_len))
        
        with torch.no_grad():
            logits = model(input_ids)
        
        logger.info(f"âœ“ æ¨¡å‹æµ‹è¯•é€šè¿‡")
        logger.info(f"  æ¨¡å‹å‚æ•°æ•°é‡: {model.get_num_params():,}")
        logger.info(f"  è¾“å…¥å½¢çŠ¶: {input_ids.shape}")
        logger.info(f"  è¾“å‡ºå½¢çŠ¶: {logits.shape}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_step():
    """æµ‹è¯•è®­ç»ƒæ­¥éª¤"""
    logger.info("=== æµ‹è¯•è®­ç»ƒæ­¥éª¤ ===")
    try:
        from data.tinystories_loader import create_dataloaders
        from model.gpt_model import GPTSmall
        import torch.nn as nn
        
        # åˆ›å»ºæ•°æ®å’Œæ¨¡å‹
        train_loader, _, tokenizer = create_dataloaders(
            batch_size=2,
            max_length=128,
            num_workers=0,
            train_subset_size=5
        )
        
        model = GPTSmall(
            vocab_size=50257,
            hidden_size=256,
            num_layers=2,
            num_heads=4,
            max_seq_len=128
        )
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        print("==åˆ›å»ºä¼˜åŒ–å™¨==")
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
        criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)
        
        # æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤
        print("==æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤==")
        batch = next(iter(train_loader))
        input_ids = batch['input_ids']
        
        # æ„é€ è¾“å…¥å’Œç›®æ ‡
        print("==æ„é€ è¾“å…¥å’Œç›®æ ‡==")
        inputs = input_ids[:, :-1]
        targets = input_ids[:, 1:]
        
        # å‰å‘ä¼ æ’­
        print("==å‰å‘ä¼ æ’­==")
        logits = model(inputs)
        loss = criterion(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))
        
        # åå‘ä¼ æ’­
        print("==åå‘ä¼ æ’­==")
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        logger.info(f"âœ“ è®­ç»ƒæ­¥éª¤æµ‹è¯•é€šè¿‡")
        logger.info(f"  æŸå¤±å€¼: {loss.item():.4f}")
        logger.info(f"  å›°æƒ‘åº¦: {torch.exp(loss).item():.2f}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— è®­ç»ƒæ­¥éª¤æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_gpu():
    """æµ‹è¯•GPUå¯ç”¨æ€§"""
    logger.info("=== æµ‹è¯•GPU ===")
    try:
        if torch.cuda.is_available():
            device = torch.device('cuda')
            logger.info(f"âœ“ GPUå¯ç”¨")
            logger.info(f"  è®¾å¤‡: {torch.cuda.get_device_name()}")
            logger.info(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
            
            # æµ‹è¯•GPUè®¡ç®—
            x = torch.randn(100, 100).to(device)
            y = torch.mm(x, x.t())
            logger.info(f"  GPUè®¡ç®—æµ‹è¯•é€šè¿‡")
            
            return True
        else:
            logger.warning("GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
            return False
    except Exception as e:
        logger.error(f"âœ— GPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_deepspeed_config():
    """æµ‹è¯•DeepSpeedé…ç½®"""
    logger.info("=== æµ‹è¯•DeepSpeedé…ç½® ===")
    try:
        import json
        config_path = "configs/ds_config_pretrain.json"
        
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config = json.load(f)
            
            logger.info(f"âœ“ DeepSpeedé…ç½®æ–‡ä»¶å­˜åœ¨")
            logger.info(f"  æ‰¹é‡å¤§å°: {config.get('train_batch_size', 'N/A')}")
            logger.info(f"  ZeROé˜¶æ®µ: {config.get('zero_optimization', {}).get('stage', 'N/A')}")
            logger.info(f"  FP16: {config.get('fp16', {}).get('enabled', False)}")
            
            return True
        else:
            logger.error(f"âœ— DeepSpeedé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
    except Exception as e:
        logger.error(f"âœ— DeepSpeedé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹ç»„ä»¶æµ‹è¯•...")
    
    tests = [
        ("GPU", test_gpu),
        ("æ•°æ®åŠ è½½å™¨", test_data_loader),
        ("æ¨¡å‹", test_model),
        ("è®­ç»ƒæ­¥éª¤", test_training_step),
        ("DeepSpeedé…ç½®", test_deepspeed_config)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            logger.error(f"æµ‹è¯• {test_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            results[test_name] = False
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    logger.info(f"\n{'='*50}")
    logger.info("=== æµ‹è¯•ç»“æœæ‘˜è¦ ===")
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        logger.info(f"{test_name:15s}: {status}")
        if not passed:
            all_passed = False
    
    if all_passed:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
    else:
        logger.info("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")
    
    return all_passed

if __name__ == "__main__":
    main()
